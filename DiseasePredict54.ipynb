{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 201.5445 - accuracy: 0.5588\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 103.2398 - accuracy: 0.5973\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 86.0125 - accuracy: 0.5407\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 80.5993 - accuracy: 0.5430\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 55.3664 - accuracy: 0.6154\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 51.7494 - accuracy: 0.6493\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 46.0038 - accuracy: 0.6538\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 33.6623 - accuracy: 0.6538\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 30.0677 - accuracy: 0.6516\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 25.7305 - accuracy: 0.7195\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 28.1217 - accuracy: 0.6855\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 22.4465 - accuracy: 0.6697\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 19.8101 - accuracy: 0.6946\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 15.4671 - accuracy: 0.7240\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 16.2249 - accuracy: 0.7557\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 13.1780 - accuracy: 0.7624\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 10.9271 - accuracy: 0.7692\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.7643 - accuracy: 0.7692\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.9329 - accuracy: 0.8054\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.2162 - accuracy: 0.8326\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.6030 - accuracy: 0.8145\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.7467 - accuracy: 0.8507\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.0032 - accuracy: 0.8552\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3366 - accuracy: 0.8484\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.9853 - accuracy: 0.8710\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.2498 - accuracy: 0.8348\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1810 - accuracy: 0.8394\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.2139 - accuracy: 0.8982\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.4939 - accuracy: 0.8824\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.8520 - accuracy: 0.8462\n",
      "I will determine the accuracy of my test data.\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 38.2896 - accuracy: 0.7299\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "Dataset= pd.read_csv(\"Training.csv\")\n",
    "\n",
    "\n",
    "Dataset=Dataset.dropna() # remove null values\n",
    "Dataset=Dataset.drop(\"Id\",axis=1) # remove sample information\n",
    "#print(Dataset.value_counts(Dataset[\"Class\"]))\n",
    "Labels=Dataset[[\"Class\"]].copy() # generate separate class dataframe\n",
    "Dataset=Dataset.drop(\"Class\",axis=1) # drop class from feature dataframe\n",
    "mapping = {'A': 1, 'B': 0} # change object from str to int \n",
    "Dataset['EJ'] = Dataset['EJ'].replace(mapping)\n",
    "#print(Dataset.shape)\n",
    "Dataset_train, Dataset_test, Labels_train, Labels_test = train_test_split(Dataset, Labels, test_size=0.5, random_state=42)\n",
    "#print(type(Dataset_train))\n",
    "sm = SMOTE(random_state=42)\n",
    "AltDataset, AltLabels = sm.fit_resample(Dataset_train, Labels_train)\n",
    "#print(AltLabels.value_counts(AltLabels[\"Class\"]))\n",
    "AltDataset = tf.convert_to_tensor(AltDataset.values, dtype=tf.float32)\n",
    "AltLabels=tf.convert_to_tensor(AltLabels.values, dtype=tf.float32)\n",
    "print(len(Labels_train))\n",
    "DiseaseModel=keras.Sequential([layers.Dense(300,activation=\"relu\"),layers.Dense(1,activation=\"sigmoid\")])\n",
    "DiseaseModel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "DiseaseModel.fit(AltDataset,AltLabels,epochs=30,batch_size=150)\n",
    "print(\"I will determine the accuracy of my test data.\")\n",
    "Evaluations=DiseaseModel.evaluate(Dataset_test,Labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([Dense(300, activation=\"relu\"), Dense(1, activation=\"sigmoid\")])\n",
    "    return model\n",
    "\n",
    "loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "num_models = 10\n",
    "models = [create_model() for _ in range(num_models)]  # Initialize models\n",
    "\n",
    "for generation in range(min(50, len(AltDataset))):  # For each generation\n",
    "    losses = []\n",
    "    for model in models:  # For each model\n",
    "        sample, label = AltDataset[generation], AltLabels[generation]\n",
    "        optimizer = tf.keras.optimizers.Adam()  # Define optimizer inside the loop\n",
    "        \n",
    "        # Train the model on the sample\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = model(sample[None, ...], training=True)  # Forward pass\n",
    "            loss = loss_function(label[None, ...], prediction)  # Compute the loss\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)  # Compute the gradients\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))  # Update the weights\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    # Find the best two models\n",
    "    best_two_models = [models[i] for i in np.argsort(losses)[:2]]\n",
    "\n",
    "    # Create 5 new models for the next generation\n",
    "    new_models = []\n",
    "    for _ in range(num_models):\n",
    "        new_model = create_model()\n",
    "        new_model.build((None, sample.shape[0]))  # Build the model to create weights\n",
    "\n",
    "       # Combine weights from the two best models\n",
    "        for i in range(len(new_model.weights)):\n",
    "            # Create a mask to select weights from the two best models\n",
    "            mask = np.random.choice([0, 1], size=new_model.weights[i].shape.as_list())\n",
    "\n",
    "            # Use the mask to select weights\n",
    "            new_weights = np.where(mask, best_two_models[0].weights[i].numpy(), best_two_models[1].weights[i].numpy())\n",
    "            \n",
    "            new_model.weights[i].assign(new_weights)\n",
    "\n",
    "        new_models.append(new_model)\n",
    "\n",
    "    models = new_models\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.sequential.Sequential object at 0x000001E98D330790>, <keras.engine.sequential.Sequential object at 0x000001E98C28FA30>, <keras.engine.sequential.Sequential object at 0x000001E98D42F670>, <keras.engine.sequential.Sequential object at 0x000001E98D472310>, <keras.engine.sequential.Sequential object at 0x000001E98C0398B0>, <keras.engine.sequential.Sequential object at 0x000001E98D3AFD00>, <keras.engine.sequential.Sequential object at 0x000001E98BE3F4C0>, <keras.engine.sequential.Sequential object at 0x000001E98BE3FD90>, <keras.engine.sequential.Sequential object at 0x000001E98FEB2DC0>, <keras.engine.sequential.Sequential object at 0x000001E98FFE57C0>]\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model 1 accuracy: 82.48175382614136%\n",
      "Model precision: 100.00%\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model 2 accuracy: 82.48175382614136%\n",
      "Model precision: 100.00%\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model 3 accuracy: 82.48175382614136%\n",
      "Model precision: 100.00%\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model 4 accuracy: 82.48175382614136%\n",
      "Model precision: 100.00%\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model 5 accuracy: 82.48175382614136%\n",
      "Model precision: 100.00%\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "Model 6 accuracy: 82.48175382614136%\n",
      "Model precision: 100.00%\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model 7 accuracy: 82.48175382614136%\n",
      "Model precision: 100.00%\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model 8 accuracy: 82.48175382614136%\n",
      "Model precision: 100.00%\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model 9 accuracy: 82.48175382614136%\n",
      "Model precision: 100.00%\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Model 10 accuracy: 82.48175382614136%\n",
      "Model precision: 100.00%\n",
      "By random chance the precision would be 17.88%\n"
     ]
    }
   ],
   "source": [
    "print(models)\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "for i, model in enumerate(models):\n",
    "    accuracy_metric = BinaryAccuracy()\n",
    "    y_pred = model.predict(Dataset_test)  # assuming x_test is your test data\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # convert probabilities to class labels (0 or 1)\n",
    "    accuracy_metric.update_state(Labels_test.values, y_pred)  # assuming y_test is your test labels\n",
    "    accuracy = accuracy_metric.result().numpy()\n",
    "    print(f\"Model {i + 1} accuracy: {accuracy * 100}%\")\n",
    "    predictions_tensor = tf.convert_to_tensor(y_pred, dtype=tf.int32)\n",
    "    precision = tf.keras.metrics.Precision()\n",
    "    precision.update_state(Labels_test.values, predictions_tensor)\n",
    "    precision_score = precision.result().numpy()\n",
    "    print(f'Model precision: {precision_score*100:.2f}%')\n",
    "\n",
    "Proportion=(Labels_test.value_counts(Labels_test[\"Class\"]))\n",
    "print(\"By random chance the precision would be {:.2f}%\".format(Proportion[1]/(Proportion[0]+Proportion[1])*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0        225\n",
      "1         49\n",
      "Name: count, dtype: int64\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Model precision: 29.51%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming `model` is your trained model\n",
    "# Assuming `X_test` is your test data and `y_test` are your test labels\n",
    "print(Labels_test.value_counts())\n",
    "# Get the model's predictions for the test dataset\n",
    "predictions = DiseaseModel.predict(Dataset_test)\n",
    "# As model.predict returns probabilities, we need to convert them to class labels\n",
    "# You can adjust the threshold according to your problem, but commonly it's 0.5 for binary classification\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Convert labels and predictions to TensorFlow tensors\n",
    "predictions_tensor = tf.convert_to_tensor(predictions, dtype=tf.int32)\n",
    "\n",
    "# Compute precision\n",
    "precision = tf.keras.metrics.Precision()\n",
    "precision.update_state(Labels_test.values, predictions_tensor)\n",
    "precision_score = precision.result().numpy()\n",
    "\n",
    "print(f'Model precision: {precision_score*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
