{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "Dataset= pd.read_csv(\"Training.csv\")\n",
    "\n",
    "\n",
    "Dataset=Dataset.dropna() # remove null values\n",
    "Dataset=Dataset.drop(\"Id\",axis=1) # remove sample information\n",
    "#print(Dataset.value_counts(Dataset[\"Class\"]))\n",
    "Labels=Dataset[[\"Class\"]].copy() # generate separate class dataframe\n",
    "Dataset=Dataset.drop(\"Class\",axis=1) # drop class from feature dataframe\n",
    "mapping = {'A': 1, 'B': 0} # change object from str to int \n",
    "Dataset['EJ'] = Dataset['EJ'].replace(mapping)\n",
    "#print(Dataset.shape)\n",
    "Dataset_train, Dataset_test, Labels_train, Labels_test = train_test_split(Dataset, Labels, test_size=0.5, random_state=42)\n",
    "#print(type(Dataset_train))\n",
    "sm = SMOTE(random_state=42)\n",
    "AltDataset, AltLabels = sm.fit_resample(Dataset_train, Labels_train)\n",
    "#print(AltLabels.value_counts(AltLabels[\"Class\"]))\n",
    "AltDataset = tf.convert_to_tensor(AltDataset.values, dtype=tf.float32)\n",
    "AltLabels=tf.convert_to_tensor(AltLabels.values, dtype=tf.float32)\n",
    "print(len(Labels_train))\n",
    "DiseaseModel=keras.Sequential([layers.Dense(300,activation=\"relu\"),layers.Dense(1,activation=\"sigmoid\")])\n",
    "DiseaseModel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "DiseaseModel.fit(AltDataset,AltLabels,epochs=30,batch_size=150)\n",
    "print(\"I will determine the accuracy of my test data.\")\n",
    "Evaluations=DiseaseModel.evaluate(Dataset_test,Labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([Dense(140, activation=\"relu\"),Dense(30, activation=\"swish\"), Dense(1, activation=\"sigmoid\")])\n",
    "    return model\n",
    "\n",
    "loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "num_models = 100\n",
    "models = [create_model() for _ in range(num_models)]  # Initialize models\n",
    "\n",
    "\n",
    "for generation in range(min(50, len(AltDataset))):  # For each generation\n",
    "    losses = []\n",
    "\n",
    "    for model in models:  # For each model\n",
    "        \n",
    "        sample, label = AltDataset[generation], AltLabels[generation]\n",
    "        optimizer = tf.keras.optimizers.Adam()  # Define optimizer inside the loop\n",
    "        \n",
    "        # Train the model on the sample\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = model(sample[None, ...], training=True)  # Forward pass\n",
    "            loss = loss_function(label[None, ...], prediction)  # Compute the loss\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)  # Compute the gradients\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))  # Update the weights\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    sorted_indices = (np.argsort(losses))[1:int((len(models)/2)+1)]\n",
    "    top_20_idx = sorted_indices[:len(models) * 20 // 100]\n",
    "    mid_40_idx = sorted_indices[len(models) * 20 // 100:len(models) * 60 // 100]\n",
    "    bottom_40_idx = sorted_indices[len(models) * 60 // 100:]\n",
    "\n",
    "    def crossover_and_create_models(parents, num_children_per_pair):\n",
    "        new_models = []\n",
    "        num_pairs = len(parents) // 2 * 2  # Ensures an even number of parents\n",
    "        for i in range(0, num_pairs, 2):  # We'll use pairs of parents\n",
    "            for _ in range(num_children_per_pair):\n",
    "                new_model = create_model()\n",
    "                new_model.build((None, sample.shape[0]))\n",
    "                for j in range(len(new_model.weights)):\n",
    "                    mask = np.random.choice([0, 1], size=new_model.weights[j].shape.as_list())\n",
    "                    new_weights = np.where(mask, models[parents[i]].weights[j].numpy(), models[parents[i + 1]].weights[j].numpy())\n",
    "                    new_model.weights[j].assign(new_weights)\n",
    "                new_models.append(new_model)\n",
    "                total_weight = sum([np.sum(w.numpy()) for w in new_model.weights])\n",
    "                #print(f\"Sum of all weights for model {_}: {total_weight}\")\n",
    "        return new_models\n",
    "\n",
    "\n",
    "    # Creating children from top 20%, mid 40%, and bottom 40%\n",
    "    #new_models_top_20 = crossover_and_create_models(top_20_idx, 3)\n",
    "    #new_models_mid_40 = crossover_and_create_models(mid_40_idx, 2)\n",
    "    #new_models_bottom_40 = crossover_and_create_models(bottom_40_idx, 1)\n",
    "    new_models=crossover_and_create_models(sorted_indices,4)\n",
    "    # Combine all the newly created models\n",
    "    #new_models = new_models_top_20 + new_models_mid_40 + new_models_bottom_40\n",
    "    \n",
    "\n",
    "    models = new_models\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models)\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "for i, model in enumerate(models):  \n",
    "      y_pred = model.predict(Dataset_test)  # Assuming Dataset_test is your test data\n",
    "      y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to class labels (0 or 1)\n",
    "\n",
    "      conf_matrix = np.zeros((2, 2), dtype=int)\n",
    "      conf_matrix[0, 0] = np.sum((Labels_test.values == 0) & (y_pred == 0))  # True Negatives (TN)\n",
    "      conf_matrix[0, 1] = np.sum((Labels_test.values == 0) & (y_pred == 1))  # False Positives (FP)\n",
    "      conf_matrix[1, 0] = np.sum((Labels_test.values == 1) & (y_pred == 0))  # False Negatives (FN)\n",
    "      conf_matrix[1, 1] = np.sum((Labels_test.values == 1) & (y_pred == 1))  # True Positives (TP)\n",
    "\n",
    "      # Extract true negatives (TN), false positives (FP), true positives (TP), and false negatives (FN) from the confusion matrix\n",
    "      TN, FP, TP, FN = conf_matrix[0, 0], conf_matrix[0, 1], conf_matrix[1, 1], conf_matrix[1, 0]\n",
    "\n",
    "      # Calculate specificity, sensitivity, precision, NPV, and accuracy\n",
    "      specificity = TN / (TN + FP)\n",
    "      sensitivity = TP / (TP + FN)\n",
    "      precision_class_one = TP / (TP + FP)\n",
    "      Negative_Predictive_Value = TN / (TN + FN)\n",
    "      accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "      # Print the metrics\n",
    "      \"\"\"\n",
    "      print(f\"Model {i+1}\")\n",
    "      print(f\"Sensitivity: {sensitivity * 100:.2f}%,\",\n",
    "            f\"Specificity: {specificity * 100:.2f}%,\",\n",
    "            f\"Accuracy: {accuracy * 100:.2f}%,\",\n",
    "            f\"Negative Predictive Value: {Negative_Predictive_Value * 100:.2f}%,\",\n",
    "            f\"Precision (Class One): {precision_class_one * 100:.2f}%\")\n",
    "      print(f\"True Negatives (TN): {TN},\",\n",
    "            f\"False Positives (FP): {FP},\",\n",
    "            f\"True Positives (TP): {TP},\",\n",
    "            f\"False Negatives (FN): {FN}\")\n",
    "      \"\"\"\n",
    "\n",
    "      if sensitivity > 0.3 and specificity >0.8:\n",
    "            print(\"Green\")\n",
    "            print(f\"Model {i+1}\")\n",
    "            print(f\"Sensitivity: {sensitivity * 100:.2f}%,\",\n",
    "                  f\"Specificity: {specificity * 100:.2f}%,\",\n",
    "                  f\"Accuracy: {accuracy * 100:.2f}%,\",\n",
    "                  f\"Negative Predictive Value: {Negative_Predictive_Value * 100:.2f}%,\",\n",
    "                  f\"Precision (Class One): {precision_class_one * 100:.2f}%\")\n",
    "            print(f\"True Negatives (TN): {TN},\",\n",
    "                  f\"False Positives (FP): {FP},\",\n",
    "                  f\"True Positives (TP): {TP},\",\n",
    "                  f\"False Negatives (FN): {FN}\")\n",
    "\n",
    "Proportion = Labels_test[\"Class\"].value_counts()\n",
    "print(\"By random chance the precision would be {:.2f}%\".format(Proportion[1] / (Proportion[0] + Proportion[1]) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming y_true and y_pred are numpy arrays representing the true labels and predicted labels, respectively.\n",
    "# 1 represents the positive class, and 0 represents the negative class.\n",
    "y_pred=model.predict(Dataset_test)\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = np.zeros((2, 2), dtype=int)\n",
    "conf_matrix[0, 0] = np.sum((Labels_test.values == 0) & (y_pred == 0))  # True Negatives (TN)\n",
    "conf_matrix[0, 1] = np.sum((Labels_test.values== 0) & (y_pred == 1))  # False Positives (FP)\n",
    "conf_matrix[1, 0] = np.sum((Labels_test.values == 1) & (y_pred == 0))  # False Negatives (FN)\n",
    "conf_matrix[1, 1] = np.sum((Labels_test.values == 1) & (y_pred == 1))  # True Positives (TP)\n",
    "\n",
    "# Extract true negatives (TN) and false positives (FP) from the confusion matrix\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "TP = conf_matrix[1, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "# Calculate specificity\n",
    "specificity = TN / (TN + FP)\n",
    "sensitivity = TP / (TP + FN)\n",
    "precision_class_one=TP/(TP+FP)\n",
    "Negative_Predictive_Value=TN/(TN+FN)\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "print(f\"Specificity: {specificity * 100:.2f}%\",\n",
    "      f\"Sensitivity: {sensitivity * 100:.2f}%\",\n",
    "      f\"Accuracy: {accuracy * 100:.2f}%\",\n",
    "      f\"Negative Predictive Value: {Negative_Predictive_Value * 100:.2f}%\",\n",
    "      f\"Precision (Class One): {precision_class_one * 100:.2f}%\")\n",
    "print(f\"True Negatives (TN): {TN}\",\n",
    "      f\"False Positives (FP): {FP}\",\n",
    "      f\"True Positives (TP): {TP}\",\n",
    "      f\"False Negatives (FN): {FN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming `model` is your trained model\n",
    "# Assuming `X_test` is your test data and `y_test` are your test labels\n",
    "y_pred = DiseaseModel.predict(Dataset_test)  # assuming x_test is your test data\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "conf_matrix = np.zeros((2, 2), dtype=int)\n",
    "conf_matrix[0, 0] = np.sum((Labels_test.values == 0) & (y_pred == 0))  # True Negatives (TN)\n",
    "conf_matrix[0, 1] = np.sum((Labels_test.values== 0) & (y_pred == 1))  # False Positives (FP)\n",
    "conf_matrix[1, 0] = np.sum((Labels_test.values == 1) & (y_pred == 0))  # False Negatives (FN)\n",
    "conf_matrix[1, 1] = np.sum((Labels_test.values == 1) & (y_pred == 1))  # True Positives (TP)\n",
    "\n",
    "# Extract true negatives (TN) and false positives (FP) from the confusion matrix\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "TP = conf_matrix[1, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "# Calculate specificity\n",
    "specificity = TN / (TN + FP)\n",
    "sensitivity = TP / (TP + FN)\n",
    "precision_class_one=TP/(TP+FP)\n",
    "Negative_Predictive_Value=TN/(TN+FN)\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "print(specificity*100,sensitivity*100,accuracy*100,Negative_Predictive_Value*100,precision_class_one*100)\n",
    "print(TN,FP,TP,FN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
