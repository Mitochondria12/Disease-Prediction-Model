{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 619.1911 - accuracy: 0.4910\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 246.7575 - accuracy: 0.4751\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 228.4127 - accuracy: 0.5226\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 167.4783 - accuracy: 0.6222\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 195.0534 - accuracy: 0.6290\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 145.4631 - accuracy: 0.6538\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 84.8205 - accuracy: 0.5747\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 80.8800 - accuracy: 0.5837\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 58.0942 - accuracy: 0.6425\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 52.7888 - accuracy: 0.6516\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 43.4536 - accuracy: 0.6109\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 30.7481 - accuracy: 0.7036\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 29.0206 - accuracy: 0.7036\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 23.6314 - accuracy: 0.6855\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 18.5017 - accuracy: 0.7466\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 15.3056 - accuracy: 0.7443\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 13.2887 - accuracy: 0.7602\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.9229 - accuracy: 0.7534\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 10.8889 - accuracy: 0.7851\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 11.5695 - accuracy: 0.7262\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 13.6978 - accuracy: 0.7511\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 11.4051 - accuracy: 0.7624\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 11.6031 - accuracy: 0.7647\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 11.8160 - accuracy: 0.7511\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 10.0439 - accuracy: 0.7647\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.9983 - accuracy: 0.8190\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.1825 - accuracy: 0.8122\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.3453 - accuracy: 0.8281\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3751 - accuracy: 0.8484\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1296 - accuracy: 0.8688\n",
      "I will determine the accuracy of my test data.\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 40.2073 - accuracy: 0.7883\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "Dataset= pd.read_csv(\"Training.csv\")\n",
    "\n",
    "\n",
    "Dataset=Dataset.dropna() # remove null values\n",
    "Dataset=Dataset.drop(\"Id\",axis=1) # remove sample information\n",
    "#print(Dataset.value_counts(Dataset[\"Class\"]))\n",
    "Labels=Dataset[[\"Class\"]].copy() # generate separate class dataframe\n",
    "Dataset=Dataset.drop(\"Class\",axis=1) # drop class from feature dataframe\n",
    "mapping = {'A': 1, 'B': 0} # change object from str to int \n",
    "Dataset['EJ'] = Dataset['EJ'].replace(mapping)\n",
    "#print(Dataset.shape)\n",
    "Dataset_train, Dataset_test, Labels_train, Labels_test = train_test_split(Dataset, Labels, test_size=0.5, random_state=42)\n",
    "#print(type(Dataset_train))\n",
    "sm = SMOTE(random_state=42)\n",
    "AltDataset, AltLabels = sm.fit_resample(Dataset_train, Labels_train)\n",
    "#print(AltLabels.value_counts(AltLabels[\"Class\"]))\n",
    "AltDataset = tf.convert_to_tensor(AltDataset.values, dtype=tf.float32)\n",
    "AltLabels=tf.convert_to_tensor(AltLabels.values, dtype=tf.float32)\n",
    "print(len(Labels_train))\n",
    "DiseaseModel=keras.Sequential([layers.Dense(300,activation=\"relu\"),layers.Dense(1,activation=\"sigmoid\")])\n",
    "DiseaseModel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "DiseaseModel.fit(AltDataset,AltLabels,epochs=30,batch_size=150)\n",
    "print(\"I will determine the accuracy of my test data.\")\n",
    "Evaluations=DiseaseModel.evaluate(Dataset_test,Labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([Dense(300, activation=\"relu\"), Dense(1, activation=\"sigmoid\")])\n",
    "    return model\n",
    "\n",
    "loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "num_models = 5\n",
    "models = [create_model() for _ in range(num_models)]  # Initialize models\n",
    "\n",
    "for generation in range(min(50, len(AltDataset))):  # For each generation\n",
    "    losses = []\n",
    "    for model in models:  # For each model\n",
    "        sample, label = AltDataset[generation], AltLabels[generation]\n",
    "        optimizer = tf.keras.optimizers.Adam()  # Define optimizer inside the loop\n",
    "        \n",
    "        # Train the model on the sample\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = model(sample[None, ...], training=True)  # Forward pass\n",
    "            loss = loss_function(label[None, ...], prediction)  # Compute the loss\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)  # Compute the gradients\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))  # Update the weights\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    # Find the best two models\n",
    "    best_two_models = [models[i] for i in np.argsort(losses)[:2]]\n",
    "\n",
    "    # Create 5 new models for the next generation\n",
    "    new_models = []\n",
    "    for _ in range(num_models):\n",
    "        new_model = create_model()\n",
    "        new_model.build((None, sample.shape[0]))  # Build the model to create weights\n",
    "\n",
    "        # Combine weights from the two best models\n",
    "        for i in range(len(new_model.weights)):\n",
    "            new_model.weights[i].assign((best_two_models[0].weights[i] + best_two_models[1].weights[i]) / 2)\n",
    "\n",
    "        new_models.append(new_model)\n",
    "\n",
    "    models = new_models\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.sequential.Sequential object at 0x000001E986FC21F0>, <keras.engine.sequential.Sequential object at 0x000001E986FA6B50>, <keras.engine.sequential.Sequential object at 0x000001E987033460>, <keras.engine.sequential.Sequential object at 0x000001E987039910>, <keras.engine.sequential.Sequential object at 0x000001E987045D60>]\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Model 1 accuracy: 81.75182342529297%\n",
      "Model precision: 40.00%\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model 2 accuracy: 81.75182342529297%\n",
      "Model precision: 40.00%\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model 3 accuracy: 81.75182342529297%\n",
      "Model precision: 40.00%\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model 4 accuracy: 81.75182342529297%\n",
      "Model precision: 40.00%\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Model 5 accuracy: 81.75182342529297%\n",
      "Model precision: 40.00%\n",
      "17.88321167883212%\n"
     ]
    }
   ],
   "source": [
    "print(models)\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "for i, model in enumerate(models):\n",
    "    accuracy_metric = BinaryAccuracy()\n",
    "    y_pred = model.predict(Dataset_test)  # assuming x_test is your test data\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # convert probabilities to class labels (0 or 1)\n",
    "    accuracy_metric.update_state(Labels_test.values, y_pred)  # assuming y_test is your test labels\n",
    "    accuracy = accuracy_metric.result().numpy()\n",
    "    print(f\"Model {i + 1} accuracy: {accuracy * 100}%\")\n",
    "    predictions_tensor = tf.convert_to_tensor(y_pred, dtype=tf.int32)\n",
    "    precision = tf.keras.metrics.Precision()\n",
    "    precision.update_state(Labels_test.values, predictions_tensor)\n",
    "    precision_score = precision.result().numpy()\n",
    "    print(f'Model precision: {precision_score*100:.2f}%')\n",
    "\n",
    "Proportion=(Labels_test.value_counts(Labels_test[\"Class\"]))\n",
    "print(str(Proportion[1]/(Proportion[0]+Proportion[1])*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0        225\n",
      "1         49\n",
      "Name: count, dtype: int64\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Model precision: 42.11%\n",
      "Through random chance the precision would be as high as 16.36% ,this demonstrates that our model with a score of 38.46% precision learns some of the global patterns not specific to the training data.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming `model` is your trained model\n",
    "# Assuming `X_test` is your test data and `y_test` are your test labels\n",
    "print(Labels_test.value_counts())\n",
    "# Get the model's predictions for the test dataset\n",
    "predictions = DiseaseModel.predict(Dataset_test)\n",
    "# As model.predict returns probabilities, we need to convert them to class labels\n",
    "# You can adjust the threshold according to your problem, but commonly it's 0.5 for binary classification\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Convert labels and predictions to TensorFlow tensors\n",
    "predictions_tensor = tf.convert_to_tensor(predictions, dtype=tf.int32)\n",
    "\n",
    "# Compute precision\n",
    "precision = tf.keras.metrics.Precision()\n",
    "precision.update_state(Labels_test.values, predictions_tensor)\n",
    "precision_score = precision.result().numpy()\n",
    "\n",
    "print(f'Model precision: {precision_score*100:.2f}%')\n",
    "Calculation=(18/110*100)\n",
    "Calculation=\"{:.2f}\".format(Calculation)\n",
    "print((\"Through random chance the precision would be as high as {A}% ,this demonstrates that our model with a score of 38.46% precision learns some of the global patterns not specific to the training data.\").format(A=Calculation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
